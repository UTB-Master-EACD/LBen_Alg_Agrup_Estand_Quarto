---
title: "LBen Algoritmos de Agrupaci√≥n"
author: "luisfflorezg"
format: 
  html:
    code-fold: true  # Permite ocultar o mostrar c√≥digo
    code-summary: "Mostrar c√≥digo"  # Texto del bot√≥n de despliegue
editor: visual
execute: 
  echo: true  # Permite mostrar/ocultar c√≥digo
  warning: false  # Oculta warnings
  message: false  # Oculta mensajes
  error: false  # Evita mostrar errores en el documento
  
toc: true
toc-title: "Contenido"
toc-depth: 3
number-sections: true
---

## Resumen

Descripcion del analisis

## Carga de Librerias

Listado de librerias utilizadas

```{r}
library(readr)
library(dplyr)
library(lubridate)
library(DT)
library(ggplot2)
library(tidyr)
library(factoextra)
library(cluster)
library(dbscan)
library(openxlsx)
library(car)
library(ggpubr)
library(FSA)
library(tidyverse)
library(e1071)

```

## Cargar Datos Iniciales

En nuestro caso el formato csv - sep ";" es el que se est√° generando desde las fuentes primarias de informaci√≥n

```{r}
  
cargar_datos <- function(archivo) {
  datos <- read_delim(archivo, delim = ";", col_types = cols(.default = "c"), locale = locale(decimal_mark = ".", grouping_mark = ","), trim_ws = TRUE)
  colnames(datos) <- trimws(colnames(datos))
  if (!all(c("fecha_hora", "consumo") %in% colnames(datos))) {
    stop("El archivo debe contener las columnas 'fecha_hora' y 'consumo'")
  }
  datos <- datos %>%
    mutate(
      fecha_hora = dmy_hm(fecha_hora),
      consumo = as.numeric(consumo),
      a√±o = as.integer(year(fecha_hora)),
      mes = month(fecha_hora, label = TRUE, abbr = TRUE),
      dia = day(fecha_hora),
      dia_sem = wday(fecha_hora, label = TRUE, abbr = FALSE, week_start = 1),
      hora = hour(fecha_hora)
    ) %>%
    select(fecha_hora, a√±o, mes, dia, dia_sem, hora, consumo)
  return(datos)
}

ruta <- "www/caso1.csv"
datos_preparados <- cargar_datos(ruta)
datatable( head (datos_preparados, 10) )
```

## Descripcion del dataset Datos Iniciales

Verificacion de la disponibilidad y formato de las variables requeridas para el analisis

```{r}
describir_datos <- function(datos) {
  resumen <- datos %>%
    summarise(
      Variable = names(.),
      Tipo = sapply(., class),
      Registros = n(),
      Valores_Unicos = sapply(., function(x) length(unique(x))),
      Valores_Faltantes = sapply(., function(x) sum(is.na(x)))
    ) %>%
    as.data.frame()
  datatable(resumen, options = list(pageLength = 10, scrollX = TRUE))
}

describir_datos(datos_preparados)
```

## Limpieza del Dataset Datos Iniciales

Eliminaci√≥n de datos faltantes

Debido a que no se utilizaran algoritmos que requieran conservar la forma de la serie de datos, es posible eliminar los registros faltantes.

```{r}
limpiar_datos <- function(datos) {
  datos_limpiados <- datos %>%
    select(-fecha_hora) %>%
    na.omit()
  return(datos_limpiados)
}

datos_limpiados <- limpiar_datos(datos_preparados)

describir_datos(datos_limpiados)

# datatable( head(datos_limpiados) )
```

## Analisis Exploratorio de Datos Iniciales

### Graficos de distribicion de frecuencia

Para la metodologia es deseable pero no es necesario que los datos esten balanceados, se requiere la presencia de la mayor cantidad de escenarios posibles (todos los dias y todas las horas), para darle sentido a los grupos que se obtendran mas adelante, la influencia del mes puede ser significativa en caso de que existan patrones de largo plazo (estaciones climaticas, operaciones temporales, entre otros), en los casos de estudio tenemos menos de un a√±o de datos.

```{r}
library(ggplot2)
library(patchwork)

graficar_distribuciones <- function(datos, titulo_size = 16, eje_size = 12) {
  # Gr√°fico de distribuci√≥n de meses
  p1 <- ggplot(datos, aes(x = mes)) +
    geom_bar(fill = "steelblue", color = "black") +
    theme_minimal(base_size = 14) +
    labs(title = "Distribuci√≥n por Mes", x = "Mes", y = "Frecuencia") +
    theme(
      plot.title = element_text(size = titulo_size, face = "bold"),
      axis.text.x = element_text(angle = 45, hjust = 1, size = eje_size),
      axis.text.y = element_text(size = eje_size),
      axis.title.x = element_text(size = eje_size),
      axis.title.y = element_text(size = eje_size)
    )

  # Gr√°fico de distribuci√≥n de d√≠as de la semana
  p2 <- ggplot(datos, aes(x = dia_sem)) +
    geom_bar(fill = "darkgreen", color = "black") +
    theme_minimal(base_size = 14) +
    labs(title = "Distribuci√≥n por D√≠a de la Semana", x = "D√≠a", y = "Frecuencia") +
    theme(
      plot.title = element_text(size = titulo_size, face = "bold"),
      axis.text.x = element_text(angle = 45, hjust = 1, size = eje_size),
      axis.text.y = element_text(size = eje_size),
      axis.title.x = element_text(size = eje_size),
      axis.title.y = element_text(size = eje_size)
    )

  # Gr√°fico de distribuci√≥n de horas
  p3 <- ggplot(datos, aes(x = factor(hora))) +
    geom_bar(fill = "darkred", color = "black") +
    theme_minimal(base_size = 14) +
    labs(title = "Distribuci√≥n por Hora", x = "Hora", y = "Frecuencia")+
    theme(
      plot.title = element_text(size = titulo_size, face = "bold"),
      axis.text.x = element_text(angle = 45, hjust = 1, size = 6),
      axis.text.y = element_text(size = eje_size),
      axis.title.x = element_text(size = eje_size),
      axis.title.y = element_text(size = eje_size)
    )

  # Ajustar el dise√±o para evitar superposici√≥n
  p1 + p2 + p3 + plot_layout(ncol = 3, guides = "collect") & theme(plot.margin = margin(10, 10, 10, 0))
}

# Llamada a la funci√≥n
graficar_distribuciones(datos_limpiados, titulo_size = 9, eje_size = 9)

```

### Tablas de distribuci√≥n de frecuencias de las variables

```{r}
library(dplyr)

generar_tablas_frecuencia <- function(datos) {
  # Funci√≥n auxiliar para calcular la frecuencia absoluta y relativa
  calcular_frecuencia <- function(variable, nombre_variable) {
    tabla <- datos %>%
      count({{ variable }}) %>%
      mutate(
        Frecuencia_Relativa = n / sum(n),
        Porcentaje = round(Frecuencia_Relativa * 100, 2)
      ) %>%
      rename(Valor = {{ variable }}, Frecuencia_Absoluta = n) %>%
      arrange(Valor)
    
    return(tabla)
  }
  
  # Generar las tablas para cada variable
  tabla_mes <- calcular_frecuencia(mes, "Mes")
  tabla_dia_sem <- calcular_frecuencia(dia_sem, "D√≠a de la Semana")
  tabla_hora <- calcular_frecuencia(hora, "Hora")

  # Retornar las tablas en una lista
  return(list(
    Tabla_Mes = tabla_mes,
    Tabla_Dia_Semana = tabla_dia_sem,
    Tabla_Hora = tabla_hora
  ))
}

# Llamada a la funci√≥n
tablas_frecuencia <- generar_tablas_frecuencia(datos_limpiados)

# Mostrar las tablas
datatable( tablas_frecuencia$Tabla_Mes )
datatable( tablas_frecuencia$Tabla_Dia_Semana )
datatable( tablas_frecuencia$Tabla_Hora )


```

### Magnitudes de la variable CONSUMO

```{r}
library(dplyr)
library(moments)  # Para curtosis y asimetr√≠a

analisis_exploratorio_consumo <- function(datos) {
  resumen <- datos %>%
    summarise(
      Minimo = round(min(consumo, na.rm = TRUE), 2),
      Q1 = round(quantile(consumo, 0.25, na.rm = TRUE), 2),
      Mediana = round(median(consumo, na.rm = TRUE), 2),
      Media = round(mean(consumo, na.rm = TRUE), 2),
      Q3 = round(quantile(consumo, 0.75, na.rm = TRUE), 2),
      Maximo = round(max(consumo, na.rm = TRUE), 2),
      Rango = round(Maximo - Minimo, 2),
      Rango_Intercuartilico = round(Q3 - Q1, 2),
      Desviacion_Estandar = round(sd(consumo, na.rm = TRUE), 2),
      Coef_Variacion = round((Desviacion_Estandar / Media) * 100, 2),
      Curtosis = round(kurtosis(consumo, na.rm = TRUE), 2),
      Asimetria = round(skewness(consumo, na.rm = TRUE), 2)
    )
  
  return(resumen)
}

# Llamada a la funci√≥n
analisis_consumo <- analisis_exploratorio_consumo(datos_limpiados)


# Mostrar la tabla con los resultados
datatable( analisis_consumo )

```

### Distribuci√≥n de la variable CONSUMO por d√≠a

(Analisis del comportamiento del consumo, se identifican 2 zonas alta y baja carga)

Comparativo General vs d√≠a

```{r}
library(ggplot2)
library(patchwork)

graficar_distribucion_dia <- function(datos, dia_especifico) {
  # Verificar que el d√≠a ingresado es v√°lido
  dias_validos <- c("lunes", "martes", "mi√©rcoles", "jueves", "viernes", "s√°bado", "domingo")
  if (!(dia_especifico %in% dias_validos)) {
    stop("El d√≠a ingresado no es v√°lido. Debe ser uno de: lunes, martes, mi√©rcoles, jueves, viernes, s√°bado o domingo.")
  }

  # Gr√°fico general (todos los d√≠as)
  p_general <- ggplot(datos, aes(x = consumo)) +
    geom_histogram(fill = "steelblue", color = "black", bins = 30) +
    theme_minimal(base_size = 14) +
    labs(title = "Distribuci√≥n General de Consumo",
         x = "Consumo", y = "Frecuencia") +
    theme(plot.title = element_text(size = 14, hjust = 0.5))

  # Gr√°fico para el d√≠a espec√≠fico
  p_dia <- ggplot(datos %>% filter(as.character(dia_sem) == dia_especifico), aes(x = consumo)) +
    geom_histogram(fill = "darkorange", color = "black", bins = 30) +
    theme_minimal(base_size = 14) +
    labs(title = paste("Distribuci√≥n de Consumo -", dia_especifico),
         x = "Consumo", y = "Frecuencia") +
    theme(plot.title = element_text(size = 14, hjust = 0.5))

  # Unir ambos gr√°ficos en una fila
  #layout <- p_general + p_dia + plot_layout(ncol = 2)
  layout <- p_general + plot_layout(ncol = 1)
  
  return(layout)
}

# Ejemplo de uso: Graficar el consumo general y para los martes
graficar_distribucion_dia(datos_limpiados, "lunes")
# graficar_distribucion_dia(datos_limpiados, "martes")
# graficar_distribucion_dia(datos_limpiados, "mi√©rcoles")
# graficar_distribucion_dia(datos_limpiados, "jueves")
# graficar_distribucion_dia(datos_limpiados, "viernes")
# graficar_distribucion_dia(datos_limpiados, "s√°bado")
# graficar_distribucion_dia(datos_limpiados, "domingo")

```

Comparativo D√≠a vs d√≠a

```{r}
library(ggplot2)
library(dplyr)
library(patchwork)

graficar_dos_dias <- function(datos, dia1, dia2) {
  # Lista de d√≠as v√°lidos
  dias_validos <- c("lunes", "martes", "mi√©rcoles", "jueves", "viernes", "s√°bado", "domingo")
  
  # Validar que los d√≠as ingresados sean correctos
  if (!(dia1 %in% dias_validos) | !(dia2 %in% dias_validos)) {
    stop("Los d√≠as ingresados no son v√°lidos. Deben ser: lunes, martes, mi√©rcoles, jueves, viernes, s√°bado o domingo.")
  }
  
  # Gr√°fico para el primer d√≠a
  p1 <- ggplot(datos %>% filter(as.character(dia_sem) == dia1), aes(x = consumo)) +
    geom_histogram(fill = "steelblue", color = "black", bins = 30) +
    theme_minimal(base_size = 14) +
    labs(title = paste("Distribuci√≥n de Consumo -", dia1),
         x = "Consumo", y = "Frecuencia") +
    theme(plot.title = element_text(size = 14, hjust = 0.5))
  
  # Gr√°fico para el segundo d√≠a
  p2 <- ggplot(datos %>% filter(as.character(dia_sem) == dia2), aes(x = consumo)) +
    geom_histogram(fill = "darkorange", color = "black", bins = 30) +
    theme_minimal(base_size = 14) +
    labs(title = paste("Distribuci√≥n de Consumo -", dia2),
         x = "Consumo", y = "Frecuencia") +
    theme(plot.title = element_text(size = 14, hjust = 0.5))
  
  # Unir ambos gr√°ficos en una fila
  layout <- p1 + p2 + plot_layout(ncol = 2)
  
  
  return(layout)
}

# Ejemplo de uso: Comparar consumo entre martes y viernes
graficar_dos_dias(datos_limpiados, "lunes", "domingo")

```

### Distribucion horaria de la variable consumo

```{r}
library(ggplot2)
library(dplyr)
library(patchwork)

graficar_general_vs_dia <- function(datos, dia) {
  # Lista de d√≠as v√°lidos
  dias_validos <- c("lunes", "martes", "mi√©rcoles", "jueves", "viernes", "s√°bado", "domingo")
  
  # Validar que el d√≠a ingresado sea correcto
  if (!(dia %in% dias_validos)) {
    stop("El d√≠a ingresado no es v√°lido. Debe ser: lunes, martes, mi√©rcoles, jueves, viernes, s√°bado o domingo.")
  }
  
  # Agrupar datos por hora y calcular promedio de consumo (todos los d√≠as)
  datos_general <- datos %>%
    group_by(hora) %>%
    summarise(consumo_promedio = mean(consumo, na.rm = TRUE))
  
  # Agrupar datos por hora pero solo para el d√≠a seleccionado
  datos_dia <- datos %>%
    filter(as.character(dia_sem) == dia) %>%
    group_by(hora) %>%
    summarise(consumo_promedio = mean(consumo, na.rm = TRUE))
  
  # Gr√°fico de la distribuci√≥n general
  p1 <- ggplot(datos_general, aes(x = hora, y = consumo_promedio)) +
    geom_line(color = "steelblue", size = 1.2) +
    geom_point(color = "black") +
    theme_minimal(base_size = 14) +
    labs(title = "General",
         x = "Hora del d√≠a", y = "Consumo Promedio") +
    scale_x_continuous(breaks = 0:23) +
    theme(plot.title = element_text(size = 14, hjust = 0.5))

  # Gr√°fico de la distribuci√≥n para el d√≠a espec√≠fico
  p2 <- ggplot(datos_dia, aes(x = hora, y = consumo_promedio)) +
    geom_line(color = "darkorange", size = 1.2) +
    geom_point(color = "black") +
    theme_minimal(base_size = 14) +
    labs(title = paste("D√≠a", dia),
         x = "Hora del d√≠a", y = "Consumo Promedio") +
    scale_x_continuous(breaks = 0:23) +
    theme(plot.title = element_text(size = 14, hjust = 0.5))

  # Unir los gr√°ficos en una fila
  #layout <- p1 + p2 + plot_layout(ncol = 2)
  layout <- p1 + plot_layout(ncol = 1)
  
  return(layout)
}

# Ejemplo de uso: General vs Martes
graficar_general_vs_dia(datos_limpiados, "lunes")

```

```{r}
graficar_dia_vs_dia <- function(datos, dia1, dia2) {
  # Lista de d√≠as v√°lidos
  dias_validos <- c("lunes", "martes", "mi√©rcoles", "jueves", "viernes", "s√°bado", "domingo")
  
  # Validar que los d√≠as ingresados sean correctos
  if (!(dia1 %in% dias_validos) | !(dia2 %in% dias_validos)) {
    stop("Los d√≠as ingresados no son v√°lidos. Deben ser: lunes, martes, mi√©rcoles, jueves, viernes, s√°bado o domingo.")
  }
  
  # Agrupar datos por hora para cada d√≠a seleccionado
  datos_dia1 <- datos %>%
    filter(as.character(dia_sem) == dia1) %>%
    group_by(hora) %>%
    summarise(consumo_promedio = mean(consumo, na.rm = TRUE))
  
  datos_dia2 <- datos %>%
    filter(as.character(dia_sem) == dia2) %>%
    group_by(hora) %>%
    summarise(consumo_promedio = mean(consumo, na.rm = TRUE))
  
  # Gr√°fico para el primer d√≠a
  p1 <- ggplot(datos_dia1, aes(x = hora, y = consumo_promedio)) +
    geom_line(color = "steelblue", size = 1.2) +
    geom_point(color = "black") +
    theme_minimal(base_size = 14) +
    labs(title = paste("Promedio Hora", dia1),
         x = "Hora del d√≠a", y = "Consumo Promedio") +
    scale_x_continuous(breaks = 0:23) +
    theme(plot.title = element_text(size = 14, hjust = 0.5))

  # Gr√°fico para el segundo d√≠a
  p2 <- ggplot(datos_dia2, aes(x = hora, y = consumo_promedio)) +
    geom_line(color = "darkorange", size = 1.2) +
    geom_point(color = "black") +
    theme_minimal(base_size = 14) +
    labs(title = paste("Promedio Hora -", dia2),
         x = "Hora del d√≠a", y = "Consumo Promedio") +
    scale_x_continuous(breaks = 0:23) +
    theme(plot.title = element_text(size = 14, hjust = 0.5))

  # Unir los gr√°ficos en una fila
  layout <- p1 + p2 + plot_layout(ncol = 2)
  
  return(layout)
}

# Ejemplo de uso: Comparar consumo entre martes y viernes
graficar_dia_vs_dia(datos_limpiados, "martes", "viernes")

```

### Identificaci√≥n estadistica y eliminaci√≥n de atipicos

Inicialmente no es recomendable borrar los atipicos hasta asegurarnos de que no sean parte de un patron de comportamiento, en este caso dichos valores corresponden a datos puntuales que no representan patrones de comportamiento.

```{r}
# Cargar librer√≠as necesarias
library(ggplot2)

graficar_boxplot <- function(datos, width = 2, height = 2) {
  p <- ggplot(datos, aes(y = consumo)) +
    geom_boxplot(fill = "steelblue", color = "black", outlier.size = 1.5) +
    theme_minimal(base_size = 10) +  # Tama√±o de fuente ajustado
    labs(title = "Boxplot de Consumo", y = "Consumo") +
    theme(
      axis.text.x = element_blank(),
      plot.margin = margin(5, 5, 5, 5)  # M√°rgenes m√°s compactos
    ) +
    coord_cartesian(clip = "off")  # Evita que se recorten puntos

  print(p)  # Mostrar el gr√°fico
  return(p)  # Retornar el gr√°fico
}

# Llamar la funci√≥n con tama√±o ajustable
# resultados_boxplot <- graficar_boxplot(datos_limpiados, width = 2, height = 2)



```

```{r, fig.width=2, fig.height=3}
# Llamar la funci√≥n con tama√±o ajustable
resultados_boxplot <- graficar_boxplot(datos_limpiados)
```

### Segmentaci√≥n de outliers

```{r}


# Funci√≥n para describir los outliers (superior e inferior)
describir_outliers <- function(datos) {
  # Calcular los cuartiles y el rango intercuart√≠lico (IQR)
  Q1 <- quantile(datos$consumo, 0.25, na.rm = TRUE)
  Q3 <- quantile(datos$consumo, 0.75, na.rm = TRUE)
  IQR <- Q3 - Q1
  
  # Calcular los l√≠mites inferior y superior para los outliers
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  
  # Filtrar los datos para los outliers
  outliers_superior <- datos %>% filter(consumo > upper_bound)
  outliers_inferior <- datos %>% filter(consumo < lower_bound)
  
  # Calcular conteo y porcentaje de outliers
  total_datos <- nrow(datos)
  
  # Tabla para los outliers superiores
  tabla_outliers_superior <- tibble(
    Rango = paste(upper_bound, "a", max(datos$consumo, na.rm = TRUE)),
    Conteo = nrow(outliers_superior),
    Porcentaje = round( (nrow(outliers_superior) / total_datos) * 100, 2)
  )
  
  # Tabla para los outliers inferiores
  tabla_outliers_inferior <- tibble(
    Rango = paste(min(datos$consumo, na.rm = TRUE), "a", lower_bound),
    Conteo = nrow(outliers_inferior),
    Porcentaje = round(  (nrow(outliers_inferior) / total_datos) * 100 , 2)
  )
  
  # Devolver las dos tablas
  return(list(
    outliers_superior = tabla_outliers_superior,
    outliers_inferior = tabla_outliers_inferior
  ))
}

# Probar la funci√≥n con el dataset
resultados_outliers <- describir_outliers(datos_limpiados)

# Ver los resultados
datatable( resultados_outliers$outliers_superior )
datatable( resultados_outliers$outliers_inferior )

```

### Tabla completa de outliers

```{r}

# Funci√≥n para describir todos los outliers con la columna de rango
describir_outliers_con_rango <- function(datos) {
  # Calcular los cuartiles y el rango intercuart√≠lico (IQR)
  Q1 <- quantile(datos$consumo, 0.25, na.rm = TRUE)
  Q3 <- quantile(datos$consumo, 0.75, na.rm = TRUE)
  IQR <- Q3 - Q1
  
  # Calcular los l√≠mites inferior y superior para los outliers
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  
  # Filtrar los outliers
  outliers <- datos %>%
    mutate(rango_outlier = case_when(
      consumo < lower_bound ~ paste("Inferior (<", lower_bound, ")"),
      consumo > upper_bound ~ paste("Superior (>", upper_bound, ")"),
      TRUE ~ "No Outlier"
    )) %>%
    filter(consumo < lower_bound | consumo > upper_bound)
  
  # Devolver la tabla de outliers con rango
  return(outliers)
}

# Probar la funci√≥n con el dataset
tabla_outliers_con_rango <- describir_outliers_con_rango(datos_limpiados)

# Ver los resultados
datatable( tabla_outliers_con_rango )


```

### Distribuci√≥n de outliers (todos los rangos)

```{r}
library(ggplot2)
library(dplyr)
library(patchwork)  # Para organizar los gr√°ficos en una fila
library(scales)     # Para formato de porcentaje

analizar_outliers_horarios_dias_distribucion <- function(datos) {
  # Validar que las columnas necesarias existen
  columnas_requeridas <- c("a√±o", "mes", "dia", "dia_sem", "hora", "consumo")
  if (!all(columnas_requeridas %in% colnames(datos))) {
    stop("El dataset debe contener las columnas: a√±o, mes, dia, dia_sem, hora y consumo")
  }
  
  # Calcular l√≠mites de outliers usando IQR
  Q1 <- quantile(datos$consumo, 0.25, na.rm = TRUE)
  Q3 <- quantile(datos$consumo, 0.75, na.rm = TRUE)
  IQR <- Q3 - Q1
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  
  # Agregar columna de detecci√≥n de outliers
  datos <- datos %>%
    mutate(es_outlier = consumo < lower_bound | consumo > upper_bound)
  
  # üìå 1Ô∏è‚É£ Proporci√≥n de outliers por hora del d√≠a
  df_outliers_hora <- datos %>%
    group_by(hora) %>%
    summarise(proporcion_outliers = mean(es_outlier, na.rm = TRUE)) 
  
  p1 <- ggplot(df_outliers_hora, aes(x = hora, y = proporcion_outliers)) +
    geom_line(color = "blue") + 
    geom_point(color = "red") +
    scale_y_continuous(labels = percent_format(accuracy = 1)) +
    theme_minimal() +
    labs(title = "Frecuencia de Outliers por Hora del D√≠a",
         x = "Hora del d√≠a",
         y = "Proporci√≥n de Outliers") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  # üìå 2Ô∏è‚É£ Proporci√≥n de outliers por d√≠a de la semana
  df_outliers_dia <- datos %>%
    group_by(dia_sem) %>%
    summarise(proporcion_outliers = mean(es_outlier, na.rm = TRUE)) 
  
  # Ordenar d√≠as de la semana correctamente
  niveles_dia_sem <- c("lunes", "martes", "mi√©rcoles", "jueves", "viernes", "s√°bado", "domingo")
  df_outliers_dia$dia_sem <- factor(df_outliers_dia$dia_sem, levels = niveles_dia_sem)

  p2 <- ggplot(df_outliers_dia, aes(x = dia_sem, y = proporcion_outliers)) +
    geom_bar(stat = "identity", fill = "steelblue") +
    scale_y_continuous(labels = percent_format(accuracy = 1)) +
    theme_minimal() +
    labs(title = "Frecuencia de Outliers por D√≠a de la Semana",
         x = "D√≠a de la semana",
         y = "Proporci√≥n de Outliers") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  # üìå 3Ô∏è‚É£ Distribuci√≥n de los valores de los outliers
  df_outliers <- datos %>%
    filter(es_outlier == TRUE)

  p3 <- ggplot(df_outliers, aes(x = consumo)) +
    geom_histogram(fill = "darkred", bins = 20, alpha = 0.7, color = "black") +
    theme_minimal() +
    labs(title = "Distribuci√≥n de Valores de Outliers",
         x = "Consumo (solo outliers)",
         y = "Frecuencia") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

  # Mostrar los 3 gr√°ficos en una misma fila
  final_plot <- p1 + p2 + p3 + plot_layout(ncol = 3)
  
  print(final_plot)  # Mostrar el gr√°fico combinado
  #return(final_plot) # Retornar el gr√°fico si se quiere guardar
}

# Ejecutar la funci√≥n con el dataset
analizar_outliers_horarios_dias_distribucion(datos_limpiados)

```

### Distribucion de outliers por rango

```{r}
# Funci√≥n ajustada para analizar outliers de un rango espec√≠fico
analizar_outliers_rango <- function(datos, rango = "superior") {
  # Validar que las columnas necesarias existen
  columnas_requeridas <- c("a√±o", "mes", "dia", "dia_sem", "hora", "consumo")
  if (!all(columnas_requeridas %in% colnames(datos))) {
    stop("El dataset debe contener las columnas: a√±o, mes, dia, dia_sem, hora y consumo")
  }
  
  # Calcular l√≠mites de outliers usando IQR
  Q1 <- quantile(datos$consumo, 0.25, na.rm = TRUE)
  Q3 <- quantile(datos$consumo, 0.75, na.rm = TRUE)
  IQR <- Q3 - Q1
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  
  # Filtrar seg√∫n el rango de outliers solicitado
  if (rango == "superior") {
    datos <- datos %>%
      mutate(es_outlier = consumo > upper_bound) %>%
      filter(es_outlier == TRUE)
  } else if (rango == "inferior") {
    datos <- datos %>%
      mutate(es_outlier = consumo < lower_bound) %>%
      filter(es_outlier == TRUE)
  } else {
    stop("El rango debe ser 'superior' o 'inferior'.")
  }

  # üìå 1Ô∏è‚É£ Proporci√≥n de outliers por hora del d√≠a
  df_outliers_hora <- datos %>%
    group_by(hora) %>%
    summarise(proporcion_outliers = mean(es_outlier, na.rm = TRUE)) 
  
  p1 <- ggplot(df_outliers_hora, aes(x = hora, y = proporcion_outliers)) +
    geom_line(color = "blue") + 
    geom_point(color = "red") +
    scale_y_continuous(labels = percent_format(accuracy = 1)) +
    theme_minimal() +
    labs(title = paste("Frecuencia de Outliers por Hora del D√≠a (", rango, ")", sep = ""),
         x = "Hora del d√≠a",
         y = "Proporci√≥n de Outliers") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  # üìå 2Ô∏è‚É£ Proporci√≥n de outliers por d√≠a de la semana
  df_outliers_dia <- datos %>%
    group_by(dia_sem) %>%
    summarise(proporcion_outliers = mean(es_outlier, na.rm = TRUE)) 
  
  # Ordenar d√≠as de la semana correctamente
  niveles_dia_sem <- c("lunes", "martes", "mi√©rcoles", "jueves", "viernes", "s√°bado", "domingo")
  df_outliers_dia$dia_sem <- factor(df_outliers_dia$dia_sem, levels = niveles_dia_sem)

  p2 <- ggplot(df_outliers_dia, aes(x = dia_sem, y = proporcion_outliers)) +
    geom_bar(stat = "identity", fill = "steelblue") +
    scale_y_continuous(labels = percent_format(accuracy = 1)) +
    theme_minimal() +
    labs(title = paste("Frecuencia de Outliers por D√≠a de la Semana (", rango, ")", sep = ""),
         x = "D√≠a de la semana",
         y = "Proporci√≥n de Outliers") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  # üìå 3Ô∏è‚É£ Distribuci√≥n de los valores de los outliers
  p3 <- ggplot(datos, aes(x = consumo)) +
    geom_histogram(fill = "darkred", bins = 20, alpha = 0.7, color = "black") +
    theme_minimal() +
    labs(title = paste("Distribuci√≥n de Valores de Outliers (", rango, ")", sep = ""),
         x = "Consumo (solo outliers)",
         y = "Frecuencia") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

  # Mostrar los 3 gr√°ficos en una misma fila
  final_plot <- p1 + p2 + p3 + plot_layout(ncol = 3)
  
  print(final_plot)  # Mostrar el gr√°fico combinado
  #return(final_plot) # Retornar el gr√°fico si se quiere guardar
}

# Ejecutar la funci√≥n con el dataset y el rango 'superior' o 'inferior'
analizar_outliers_rango(datos_limpiados, rango = "superior")
analizar_outliers_rango(datos_limpiados, rango = "inferior")


```

### Eliminacion de outliers

```{r}
# Eliminacion de outliers (si aplica) #####
eliminar_outliers <- function(datos, columna = "consumo") {
  # Calcular cuartiles y rango intercuart√≠lico
  Q1 <- quantile(datos[[columna]], 0.25, na.rm = TRUE)
  Q3 <- quantile(datos[[columna]], 0.75, na.rm = TRUE)
  IQR_value <- Q3 - Q1
  
  # Definir l√≠mites para detectar outliers
  limite_inferior <- Q1 - 1.5 * IQR_value
  limite_superior <- Q3 + 1.5 * IQR_value
  
  # Filtrar datos dentro de los l√≠mites
  datos_sin_outliers <- datos[datos[[columna]] >= limite_inferior & datos[[columna]] <= limite_superior, ]
  
  return(datos_sin_outliers)
}

# L√≠nea de prueba
datos_limpios_NA_OUT <- eliminar_outliers(datos_limpiados)


```

```{r}

# Llamada a la funci√≥n
analisis_consumo_NA_OUT <- analisis_exploratorio_consumo(datos_limpios_NA_OUT)






```

### Comparativo descripcion de datos

Con outliers

```{r}
# Mostrar la tabla con los resultados
datatable( analisis_consumo )

```

sin outliers

```{r}
datatable( analisis_consumo_NA_OUT )
```

## Preparaci√≥n para Identificacion de Grupos (Normalizaci√≥n)

```{r}
# Normalizar los datos de consumo (Z score mantiene la distribucion de los datos) #####

normalizar_consumo <- function(datos, metodo = "zscore") {
  # Verificar si la columna 'consumo' existe
  if (!"consumo" %in% colnames(datos)) {
    stop("El dataset no contiene la columna 'consumo'.")
  }
  
  # Normalizar seg√∫n el m√©todo elegido
  if (metodo == "zscore") {
    datos <- datos %>%
      mutate(consumo_normalizado = (consumo - mean(consumo, na.rm = TRUE)) / sd(consumo, na.rm = TRUE))
  } else if (metodo == "minmax") {
    datos <- datos %>%
      mutate(consumo_normalizado = (consumo - min(consumo, na.rm = TRUE)) / 
               (max(consumo, na.rm = TRUE) - min(consumo, na.rm = TRUE)))
  } else {
    stop("M√©todo no v√°lido. Usa 'zscore' o 'minmax'.")
  }
  
  return(datos)
}

# Ejemplo de uso:
datos_normalizados <- normalizar_consumo(datos_limpios_NA_OUT, metodo = "zscore")

datatable( head(datos_normalizados) )


```

## Calculo del numero Optimo de Grupos

Estadisticos de calculo

```{r}

# Librer√≠as necesarias
library(ggplot2)
library(factoextra)
library(cluster)
library(DT)

# Funci√≥n para calcular K √≥ptimo y generar gr√°fico
calcular_k_optimo_grafico <- function(dataset, metodo, k_max = 10) {
  datos <- dataset %>% select(consumo_normalizado)
  
  if (metodo == "codo") {
    wss <- sapply(1:k_max, function(k) {
      kmeans(datos, centers = k, nstart = 10)$tot.withinss
    })
    df_wss <- data.frame(K = 1:k_max, WSS = wss)
    grafico <- ggplot(df_wss, aes(x = K, y = WSS)) +
      geom_point() + geom_line() + ggtitle("M√©todo del Codo") +
      xlab("N√∫mero de Clusters") + ylab("Suma de cuadrados intra-cluster")
  }
  
  else if (metodo == "silhouette") {
    sil_width <- sapply(2:k_max, function(k) {
      km <- kmeans(datos, centers = k, nstart = 10)
      mean(silhouette(km$cluster, dist(datos))[, 3])
    })
    df_sil <- data.frame(K = 2:k_max, Silhouette = sil_width)
    grafico <- ggplot(df_sil, aes(x = K, y = Silhouette)) +
      geom_point() + geom_line() + ggtitle("M√©todo de Silhouette") +
      xlab("N√∫mero de Clusters") + ylab("Coeficiente Silhouette Promedio")
  }
  
  else if (metodo == "gap_stat") {
    gap_stat <- clusGap(datos, FUN = kmeans, nstart = 10, K.max = k_max, B = 50)
    grafico <- fviz_gap_stat(gap_stat)
  }
  
  else {
    stop("M√©todo no reconocido. Usa 'codo', 'silhouette' o 'gap_stat'")
  }
  
  print(grafico)
}


calcular_k_optimo_tabla <- function(dataset, metodo, k_max = 10) {
  datos <- dataset %>% select(consumo_normalizado)
  
  if (metodo == "codo") {
    wss <- sapply(1:k_max, function(k) {
      kmeans(datos, centers = k, nstart = 10)$tot.withinss
    })
    resultados <- data.frame(K = 1:k_max, WSS = wss)
  }
  
  else if (metodo == "silhouette") {
    sil_width <- sapply(2:k_max, function(k) {
      km <- kmeans(datos, centers = k, nstart = 10)
      mean(silhouette(km$cluster, dist(datos))[, 3])
    })
    resultados <- data.frame(K = 2:k_max, Silhouette = sil_width)
  }
  
  else if (metodo == "gap_stat") {
    gap_stat <- clusGap(datos, FUN = kmeans, nstart = 10, K.max = k_max, B = 50)
    resultados <- data.frame(K = 1:k_max, GAP = gap_stat$Tab[, "gap"], SE = gap_stat$Tab[, "SE.sim"])
  }
  
  else {
    stop("M√©todo no reconocido. Usa 'codo', 'silhouette' o 'gap_stat'")
  }
  
  DT::datatable(resultados, options = list(pageLength = 5)) # No usar print()
}

```

Metodo del Codo

```{r, fig.width=10, fig.height=3}
# Llamar las funciones con el dataset normalizado
calcular_k_optimo_grafico(datos_normalizados, metodo = "codo")

```

```{r}
calcular_k_optimo_tabla(datos_normalizados, metodo = "codo")
```

Metodo de Silhouette

```{r, fig.width=10, fig.height=3}
# Llamar las funciones con el dataset normalizado
calcular_k_optimo_grafico(datos_normalizados, metodo = "silhouette")

```

```{r}
calcular_k_optimo_tabla(datos_normalizados, metodo = "silhouette")
```

Metodo de gap_stat

```{r, fig.width=10, fig.height=3}
# Llamar las funciones con el dataset normalizado
calcular_k_optimo_grafico(datos_normalizados, metodo = "gap_stat")

```

```{r}
calcular_k_optimo_tabla(datos_normalizados, metodo = "gap_stat")
```

Numero optimo de grupos

```{r}

# Funci√≥n para recomendar el n√∫mero √≥ptimo de clusters #####

library(cluster)
library(factoextra)
library(dplyr)
library(DT)

determinar_num_clusters <- function(data, max_k = 10) {
  
  # Elbow Method (WCSS - Within Cluster Sum of Squares)
  elbow <- fviz_nbclust(data, kmeans, method = "wss", k.max = max_k)$data
  opt_k_elbow <- which.max(diff(diff(elbow$y))) + 1  # Encontrar el "codo"
  
  # Silhouette Method
  silhouette <- fviz_nbclust(data, kmeans, method = "silhouette", k.max = max_k)$data
  opt_k_silhouette <- silhouette$clusters[which.max(silhouette$y)]
  
  # Gap Statistic
  gap_stat <- clusGap(data, FUN = kmeans, K.max = max_k, B = 50)
  opt_k_gap <- maxSE(gap_stat$Tab[, "gap"], gap_stat$Tab[, "SE.sim"])  # Regla de 1SE
  
  # Crear tabla con los resultados de cada m√©trica
  resultados <- data.frame(
    Metodo = c("Elbow", "Silhouette", "Gap Statistic"),
    K_Optimo = c(opt_k_elbow, opt_k_silhouette, opt_k_gap)
  )
  
  # Ranking de n√∫mero de clusters (basado en cu√°ntas veces aparece cada valor)
  ranking <- resultados %>%
    count(K_Optimo, name = "Frecuencia") %>%
    arrange(desc(Frecuencia), K_Optimo)
  
  # Retornar las tablas para su visualizaci√≥n en Quarto
  list(Resultados = resultados, Ranking = ranking, Gap_Stat = gap_stat)
}

# Ejecutar la funci√≥n con datos normalizados
resultado <- determinar_num_clusters(datos_normalizados[, "consumo_normalizado"])

# Mostrar tablas en Quarto
resultado$Resultados |> DT::datatable()
resultado$Ranking |> DT::datatable()

```

## Creaci√≥n de Grupos

### Clusterizaci√≥n

```{r}
# Funci√≥n para aplicar clustering#####

# Cargar librer√≠as necesarias
library(cluster)
library(factoextra)
library(dplyr)
library(DT)
library(dbscan)



aplicar_clustering <- function(datos, num_clusters, metodo = "kmeans") {
  
  # Seleccionar solo la variable de consumo normalizado para la agrupaci√≥n
  datos_clustering <- datos %>% select(consumo_normalizado)
  
  # Aplicar el algoritmo de clustering seg√∫n el m√©todo seleccionado
  if (metodo == "kmeans") {
    modelo <- kmeans(datos_clustering, centers = num_clusters, nstart = 25)
    datos$cluster <- as.factor(modelo$cluster)
  } else if (metodo == "hclust") {
    distancia <- dist(datos_clustering, method = "euclidean")
    jerarquico <- hclust(distancia, method = "ward.D2")
    datos$cluster <- as.factor(cutree(jerarquico, k = num_clusters))
  } else if (metodo == "dbscan") {
    library(dbscan)
    modelo <- dbscan(datos_clustering, eps = 0.2, minPts = 5)
    datos$cluster <- as.factor(modelo$cluster)
  } else {
    stop("M√©todo no soportado. Usa 'kmeans', 'hclust' o 'dbscan'.")
  }
  
  # Mostrar la tabla en formato DT
  tabla_resultado <- datatable(datos, options = list(pageLength = 10, scrollX = TRUE))
  
  print(tabla_resultado)  # Mostrar la tabla
  
  return(datos)  # Retornar el dataset con la columna de cluster asignado
}



```

```{r}

datos_clusterizados <- aplicar_clustering(datos_normalizados, num_clusters = 2, metodo = "kmeans")

datatable(datos_clusterizados)
```

### Validaci√≥n de Grupos

Pruebas de normalidad y de homocedasticidad

```{r}
#   Validacion de CLuster (Metodos Estadisticos) #####

# Prueba de Normalidad y de Homocedasticidad #####
#(para selecccionar: ANOVA o Kruskal-Wallis)

library(dplyr)
library(car)  # Para la prueba de Levene
library(ggpubr)  # Para Shapiro-Wilk

validar_supuestos_clusters <- function(datos_clusterizados) {
  resultados <- list()
  
  # Verificar normalidad por cluster
  normalidad <- datos_clusterizados %>% 
    group_by(cluster) %>% 
    summarise(p_valor = shapiro.test(consumo)$p.value) %>% 
    mutate(resultado = ifelse(p_valor > 0.05, "Normal", "No Normal"))
  
  # Verificar homocedasticidad
  levene_pvalor <- leveneTest(consumo ~ cluster, data = datos_clusterizados)$"Pr(>F)"[1]
  homocedasticidad <- ifelse(levene_pvalor > 0.05, "Varianzas Iguales", "Varianzas Diferentes")
  
  # Determinar prueba estad√≠stica a utilizar
  if (all(normalidad$resultado == "Normal") & homocedasticidad == "Varianzas Iguales") {
    prueba_recomendada <- "ANOVA"
  } else {
    prueba_recomendada <- "Kruskal-Wallis"
  }
  
  # Crear mensaje para el usuario
  mensaje <- paste0(
    "Resultados de las pruebas:\n",
    "- Normalidad por cluster: ", paste(normalidad$cluster, normalidad$resultado, sep = " -> ", collapse = ", "), "\n",
    "- Homocedasticidad (Levene test): ", homocedasticidad, "\n",
    "\nRecomendaci√≥n: Se sugiere usar la prueba de ", prueba_recomendada, "."
  )
  
  return(mensaje)
}

# Ejemplo de uso
resultado <- validar_supuestos_clusters(datos_clusterizados)
cat(resultado)
```

Pruebas de Anova o de Kruskal-Wallis

```{r}
# Prueba de Anova o de Kruskal para validacion de cluster #####

realizar_prueba_clusters <- function(datos, metodo = "ANOVA") {
  library(dplyr)
  library(tidyr)
  library(ggpubr)
  
  # Verificar que el m√©todo ingresado sea v√°lido
  if (!metodo %in% c("ANOVA", "Kruskal-Wallis")) {
    stop("M√©todo no v√°lido. Use 'ANOVA' o 'Kruskal-Wallis'.")
  }
  
  # Convertir cluster a factor si no lo es
  datos$cluster <- as.factor(datos$cluster)
  
  resultado <- NULL
  mensaje <- ""
  
  if (metodo == "ANOVA") {
    # ANOVA asume normalidad y homocedasticidad, se recomienda usar solo si las pruebas previas lo confirman
    prueba_anova <- aov(consumo ~ cluster, data = datos)
    resultado <- summary(prueba_anova)
    p_valor <- summary(prueba_anova)[[1]][["Pr(>F)"]][1]
    
    if (p_valor < 0.05) {
      mensaje <- "El ANOVA indica diferencias significativas entre los clusters (p < 0.05). Se recomienda una prueba post hoc como Tukey HSD para identificar diferencias espec√≠ficas."
    } else {
      mensaje <- "El ANOVA no detect√≥ diferencias significativas entre los clusters (p >= 0.05). No se requiere prueba post hoc."
    }
  } else {
    # Kruskal-Wallis para datos no normales o heteroced√°sticos
    prueba_kruskal <- kruskal.test(consumo ~ cluster, data = datos)
    resultado <- prueba_kruskal
    p_valor <- prueba_kruskal$p.value
    
    if (p_valor < 0.05) {
      mensaje <- "La prueba de Kruskal-Wallis indica diferencias significativas entre los clusters (p < 0.05). Se recomienda una prueba post hoc como Dunn para comparaciones espec√≠ficas."
    } else {
      mensaje <- "La prueba de Kruskal-Wallis no detect√≥ diferencias significativas entre los clusters (p >= 0.05). No se requiere prueba post hoc."
    }
  }
  
  return(list(Resultados = resultado, Interpretaci√≥n = mensaje))
}

# Ejemplo de uso
resultado_prueba <- realizar_prueba_clusters(datos_clusterizados, metodo = "Kruskal-Wallis")
print(resultado_prueba$Resultados)
cat(resultado_prueba$Interpretaci√≥n)
```

Prueba Posthoc Dunn

```{r}
# Prueba Posthoc Dunn #####

library(FSA)  # Para la prueba de Dunn
library(dplyr)

realizar_prueba_posthoc <- function(datos_clusterizados) {
  # Verificar si hay m√°s de 2 clusters
  num_clusters <- length(unique(datos_clusterizados$cluster))
  
  if (num_clusters < 2) {
    return("La prueba post hoc no es necesaria, ya que solo hay un cluster.")
  }
  
  # Aplicar la prueba de Dunn con correcci√≥n de Bonferroni
  prueba_dunn <- dunnTest(consumo ~ cluster, data = datos_clusterizados, method = "bonferroni")
  
  # Extraer los resultados
  resultados <- prueba_dunn$res
  
  # Formatear salida
  interpretacion <- resultados %>% 
    mutate(Interpretaci√≥n = ifelse(P.adj < 0.05, "Diferencia significativa", "No significativa"))
  
  return(list(Resultados = resultados, Interpretaci√≥n = interpretacion))
}

# Prueba de la funci√≥n
resultado_posthoc <- realizar_prueba_posthoc(datos_clusterizados)
# print(resultado_posthoc$Resultados)
# print(resultado_posthoc$Interpretaci√≥n)

datatable((resultado_posthoc$Interpretaci√≥n))
```

### Exploraci√≥n e interpretaci√≥n de grupos

Exploraci√≥n

funcion auxiliar para establecer colores

```{r}
#funcion auxiliar para establecer colores

library(ggplot2)
library(dplyr)
library(lubridate)
library(patchwork)
library(scales)  # Para colores hue_pal()

# Funci√≥n para obtener colores consistentes
obtener_colores_clusters <- function(datos_clusterizados) {
  clusters_unicos <- sort(unique(datos_clusterizados$cluster))  # Ordenar clusters √∫nicos
  num_clusters <- length(clusters_unicos)

  # Definir los dos primeros colores fijos
  colores_fijos <- c("1" = "blue", "2" = "red")  

  # Si hay m√°s clusters, generar colores adicionales con hue_pal()
  if (num_clusters > 2) {
    clusters_adicionales <- setdiff(clusters_unicos, c(1, 2))
    colores_extra <- hue_pal()(length(clusters_adicionales))  # Colores adicionales
    nombres_clusters_extra <- as.character(clusters_adicionales)
    nombres_colores_extra <- setNames(colores_extra, nombres_clusters_extra)

    # Combinar colores fijos con los adicionales
    colores_finales <- c(colores_fijos, nombres_colores_extra)
  } else {
    colores_finales <- colores_fijos
  }

  return(colores_finales)
}
```

#### Series

```{r, fig.width=10, fig.height=4}
# --- Funci√≥n para Graficar Series Temporales ---
graficar_serie_temporal <- function(datos_clusterizados, n_datos = NULL) {
  datos_clusterizados <- datos_clusterizados %>%
    mutate(fecha_hora = make_datetime(a√±o, as.numeric(mes), dia, hora)) %>%
    arrange(fecha_hora)

  if (!is.null(n_datos)) {
    datos_clusterizados <- datos_clusterizados %>% slice_head(n = n_datos)
  }

  colores_finales <- obtener_colores_clusters(datos_clusterizados)  # Obtener colores fijos

  # Gr√°fico 1: Serie temporal sin cluster
  p1 <- ggplot(datos_clusterizados, aes(x = fecha_hora, y = consumo)) +
    geom_line(color = "black", size = 1.2) +
    labs(title = "Serie Temporal de Consumo (Sin Cluster)", x = "Fecha y Hora", y = "Consumo") +
    theme_minimal(base_size = 12)

  # Gr√°fico 2: Serie temporal con color por cluster
  p2 <- ggplot(datos_clusterizados, aes(x = fecha_hora, y = consumo, color = factor(cluster), group = 1)) +
    geom_line(size = 1.2) +
    scale_color_manual(values = colores_finales) +
    labs(title = "Serie Temporal de Consumo (Por Cluster)", x = "Fecha y Hora", y = "Consumo", color = "Cluster") +
    theme_minimal(base_size = 12)

  p1 + p2  # Usar Patchwork para mostrar en la misma fila
}

# üîπ **Ejemplo de uso**:  
graficar_serie_temporal(datos_clusterizados, n_datos = 7*24)

```

```{r, fig.width=10, fig.height=4}

# --- Funci√≥n para Graficar Series Temporales ---
#version anterior


# library(ggplot2)
# library(dplyr)
# library(lubridate)
# library(patchwork)  # Para organizar los gr√°ficos en una fila
# 
# graficar_serie_temporal <- function(datos_clusterizados, n_datos = NULL) {
#   # Crear variable fecha_hora combinando a√±o, mes, d√≠a y hora
#   datos_clusterizados <- datos_clusterizados %>%
#     mutate(fecha_hora = make_datetime(a√±o, as.numeric(mes), dia, hora)) %>%
#     arrange(fecha_hora)  # Ordenar cronol√≥gicamente
# 
#   # Filtrar si se especifica un n√∫mero de datos a graficar
#   if (!is.null(n_datos)) {
#     datos_clusterizados <- datos_clusterizados %>% slice_head(n = n_datos)
#   }
#   
#   # Obtener los clusters √∫nicos en los datos
#   clusters_unicos <- sort(unique(datos_clusterizados$cluster))
#   
#   # Definir colores espec√≠ficos para los primeros dos clusters
#   colores_fijos <- c("1" = "blue", "2" = "red")  # Azul y rojo para los clusters 1 y 2
#   
#   # Si hay m√°s clusters, asignarles colores din√°micos
#   if (length(clusters_unicos) > 2) {
#     clusters_adicionales <- setdiff(clusters_unicos, c(1, 2))
#     colores_extra <- scales::hue_pal()(length(clusters_adicionales))  # Genera colores para los dem√°s
#     nombres_clusters_extra <- as.character(clusters_adicionales)
#     nombres_colores_extra <- setNames(colores_extra, nombres_clusters_extra)
#     
#     # Combinar los colores fijos con los adicionales
#     colores_finales <- c(colores_fijos, nombres_colores_extra)
#   } else {
#     colores_finales <- colores_fijos
#   }
# 
#   # Personalizaci√≥n de tama√±os
#   tama√±o_titulo <- 14
#   tama√±o_ejes <- 12
#   tama√±o_leyenda <- 12
# 
#   # Gr√°fico 1: Serie temporal en negro (sin cluster)
#   p1 <- ggplot(datos_clusterizados, aes(x = fecha_hora, y = consumo)) +
#     geom_line(color = "black", size = 1.2) +
#     labs(title = "Serie Temporal de Consumo (Sin Cluster)", x = "Fecha y Hora", y = "Consumo") +
#     theme_minimal(base_size = 12) +
#     theme(
#       plot.title = element_text(size = tama√±o_titulo),
#       axis.title = element_text(size = tama√±o_ejes),
#       axis.text = element_text(size = tama√±o_ejes)
#     )
#   
#   # Gr√°fico 2: Serie temporal con color por cluster
#   p2 <- ggplot(datos_clusterizados, aes(x = fecha_hora, y = consumo, color = factor(cluster), group = 1)) +
#     geom_line(size = 1.2) +
#     scale_color_manual(values = colores_finales) +  # Usar los colores definidos
#     labs(title = "Serie Temporal de Consumo (Por Cluster)", x = "Fecha y Hora", y = "Consumo", color = "Cluster") +
#     theme_minimal(base_size = 12) +
#     theme(
#       plot.title = element_text(size = tama√±o_titulo),
#       axis.title = element_text(size = tama√±o_ejes),
#       axis.text = element_text(size = tama√±o_ejes),
#       legend.text = element_text(size = tama√±o_leyenda),
#       legend.title = element_text(size = tama√±o_leyenda)
#     )
#   
#   # Unir los dos gr√°ficos en una sola fila
#   p1 + p2  # Patchwork los coloca en la misma fila
# }
# 
# # üîπ **Ejemplo de uso**:  
# graficar_serie_temporal(datos_clusterizados, n_datos = 7*24)

```

#### boxplots

```{r, fig.width=10, fig.height=4}

# --- Funci√≥n para Graficar Boxplots ---
graficar_boxplot_clusters <- function(datos_clusterizados, alpha_puntos = 0.5, tama√±o_puntos = 2) {
  if (!"cluster" %in% colnames(datos_clusterizados)) {
    stop("El dataset no contiene una columna llamada 'cluster'.")
  }

  colores_finales <- obtener_colores_clusters(datos_clusterizados)  # Obtener colores fijos

  p <- ggplot(datos_clusterizados, aes(x = factor(cluster), y = consumo, fill = factor(cluster))) +
    geom_boxplot(alpha = 0.6, outlier.color = "black", outlier.shape = 16) +
    geom_jitter(aes(color = factor(cluster)), width = 0.05, alpha = alpha_puntos, size = tama√±o_puntos) +
    scale_fill_manual(values = colores_finales) +
    scale_color_manual(values = colores_finales) +
    theme_minimal(base_size = 12) +
    labs(title = "Boxplots del Consumo por Cluster", x = "Cluster", y = "Consumo") +
    theme(legend.position = "none")

  print(p)
}

# üìå **Ejemplo de uso**
graficar_boxplot_clusters(datos_clusterizados, alpha_puntos = 0.3, tama√±o_puntos = 2)
```

```{r, fig.width=10, fig.height=4}

#version anterior

# library(ggplot2)
# library(dplyr)
# 
# graficar_boxplot_clusters <- function(datos_clusterizados, alpha_puntos = 0.5, tama√±o_puntos = 2) {
#   # Verificar si el dataset tiene la columna "cluster"
#   if (!"cluster" %in% colnames(datos_clusterizados)) {
#     stop("El dataset no contiene una columna llamada 'cluster'. Aseg√∫rate de que los datos est√©n correctamente clusterizados.")
#   }
#   
#   # Obtener los clusters √∫nicos ordenados
#   clusters_unicos <- sort(unique(datos_clusterizados$cluster))
#   
#   # Definir colores espec√≠ficos para los primeros dos clusters
#   colores_fijos <- c("1" = "blue", "2" = "red")  # Azul y rojo para los clusters 1 y 2
#   
#   # Si hay m√°s clusters, asignarles colores din√°micos
#   if (length(clusters_unicos) > 2) {
#     clusters_adicionales <- setdiff(clusters_unicos, c(1, 2))
#     colores_extra <- scales::hue_pal()(length(clusters_adicionales))  # Genera colores para los dem√°s
#     nombres_clusters_extra <- as.character(clusters_adicionales)
#     nombres_colores_extra <- setNames(colores_extra, nombres_clusters_extra)
#     
#     # Combinar los colores fijos con los adicionales
#     colores_finales <- c(colores_fijos, nombres_colores_extra)
#   } else {
#     colores_finales <- colores_fijos
#   }
# 
#   # Personalizaci√≥n de tama√±os
#   tama√±o_titulo <- 14
#   tama√±o_ejes <- 12
# 
#   # Crear el gr√°fico de boxplot con dispersi√≥n
#   p <- ggplot(datos_clusterizados, aes(x = factor(cluster), y = consumo, fill = factor(cluster))) +
#     geom_boxplot(alpha = 0.6, outlier.color = "black", outlier.shape = 16) +  # Boxplot
#     geom_jitter(aes(color = factor(cluster)), width = 0.05, alpha = alpha_puntos, size = tama√±o_puntos) +  # Dispersi√≥n
#     scale_fill_manual(values = colores_finales) +  # Aplicar colores a los boxplots
#     scale_color_manual(values = colores_finales) +  # Aplicar colores a los puntos
#     theme_minimal(base_size = 12) +
#     labs(title = "Boxplots del Consumo por Cluster",
#          x = "Cluster",
#          y = "Consumo",
#          fill = "Cluster",
#          color = "Cluster") +
#     theme(
#       plot.title = element_text(size = tama√±o_titulo),
#       axis.title = element_text(size = tama√±o_ejes),
#       axis.text = element_text(size = tama√±o_ejes),
#       legend.position = "none"  # Oculta la leyenda para evitar redundancia
#     )
#   
#   print(p)  # Mostrar el gr√°fico
# }
# 
# # üìå **Ejemplo de uso**
# graficar_boxplot_clusters(datos_clusterizados, alpha_puntos = 0.3, tama√±o_puntos = 2)

```

#### estadisticos boxplots

```{r}
library(dplyr)
library(DT)

calcular_estadisticas_clusters <- function(datos_clusterizados) {
  # Verificar si el dataset tiene la columna "cluster"
  if (!"cluster" %in% colnames(datos_clusterizados)) {
    stop("El dataset no contiene una columna llamada 'cluster'. Aseg√∫rate de que los datos est√©n correctamente clusterizados.")
  }
  
  # Calcular estad√≠sticas por cluster
  resumen_clusters <- datos_clusterizados %>%
    group_by(cluster) %>%
    summarise(
      Min = min(consumo, na.rm = TRUE),
      Max = max(consumo, na.rm = TRUE),
      Promedio = mean(consumo, na.rm = TRUE),
      Mediana = median(consumo, na.rm = TRUE),
      SD = sd(consumo, na.rm = TRUE),
      IQR = IQR(consumo, na.rm = TRUE),
      .groups = "drop"
    )
  
  # Mostrar la tabla con formato interactivo
  datatable(resumen_clusters, options = list(pageLength = 5))
}

# üìå **Ejemplo de uso**
calcular_estadisticas_clusters(datos_clusterizados)

```

Incluir observaciones del analisis exploratorio hasta este punto

#### Probabilidad de Pertenencia

Incluir explicacion del metodo y la necesidad para la creacion de las matrices absolutas y probables, paso previo para decidir si editar o no los grupos

```{r}
# Probabilidad de pertenencia #####

# Funci√≥n para calcular la probabilidad de pertenencia con clustering difuso

library(tidyverse)
library(e1071)  # Para clustering difuso (Fuzzy C-Means)

calcular_probabilidad_fuzzy <- function(datos, num_clusters) {
  
  # Seleccionar solo la variable de consumo normalizado para la agrupaci√≥n
  datos_clustering <- datos %>% select(consumo_normalizado)
  
  # Aplicar Fuzzy C-Means con el n√∫mero de clusters especificado
  modelo_fuzzy <- cmeans(datos_clustering, centers = num_clusters, m = 2, iter.max = 100, method = "cmeans")
  
  # Obtener las probabilidades de pertenencia
  probabilidades <- as.data.frame(modelo_fuzzy$membership)
  colnames(probabilidades) <- paste0("cluster_", 1:num_clusters)
  
  # Agregar las probabilidades al dataset original
  datos_fuzzy <- cbind(datos, probabilidades )
  
  return(datos_fuzzy)
}


```

```{r}
datos_con_probabilidad <- calcular_probabilidad_fuzzy(datos_clusterizados, num_clusters = 2)
datatable(datos_con_probabilidad)
```

grafico densidad de distribucion de consumo

```{r}
library(ggplot2)

graficar_densidad_clusters <- function(datos_clusterizados) {
  # Verificar si el dataset tiene la columna "cluster"
  if (!"cluster" %in% colnames(datos_clusterizados)) {
    stop("El dataset no contiene una columna llamada 'cluster'. Aseg√∫rate de que los datos est√©n correctamente clusterizados.")
  }
  
  # Verificar si la columna "consumo" existe
  if (!"consumo" %in% colnames(datos_clusterizados)) {
    stop("El dataset no contiene una columna llamada 'consumo'. Aseg√∫rate de que los datos est√©n correctamente estructurados.")
  }
  
  # Convertir cluster a factor si a√∫n no lo es
  datos_clusterizados$cluster <- as.factor(datos_clusterizados$cluster)

  # Obtener colores seg√∫n la l√≥gica establecida
  colores_finales <- obtener_colores_clusters(datos_clusterizados)

  # Crear el gr√°fico de densidad con colores personalizados
  p <- ggplot(datos_clusterizados, aes(x = consumo, color = cluster, fill = cluster)) +
    geom_density(alpha = 0.4) +
    scale_color_manual(values = colores_finales) + 
    scale_fill_manual(values = colores_finales) +
    theme_minimal() +
    labs(title = "Distribuci√≥n de Densidad del Consumo por Cluster",
         x = "Consumo",
         y = "Densidad",
         color = "Cluster",
         fill = "Cluster") +
    theme(legend.position = "top")
  
  print(p) # Mostrar el gr√°fico
}

# üìå **Ejemplo de uso**
graficar_densidad_clusters(datos_clusterizados)


```

Grafico densidad de distribucion por horas

```{r}
library(ggplot2)

graficar_densidad_horas <- function(datos_clusterizados) {
  # Verificar si el dataset tiene las columnas necesarias
  if (!all(c("hora", "consumo", "cluster") %in% colnames(datos_clusterizados))) {
    stop("El dataset debe contener las columnas 'hora', 'consumo' y 'cluster'.")
  }
  
  # Obtener colores personalizados seg√∫n la funci√≥n auxiliar
  colores <- obtener_colores_clusters(datos_clusterizados)
  
  # Crear el gr√°fico de densidad con las horas en el eje X
  p <- ggplot(datos_clusterizados, aes(x = hora, color = factor(cluster), fill = factor(cluster))) +
    geom_density(alpha = 0.4) +
    scale_color_manual(values = colores) + 
    scale_fill_manual(values = colores) +
    theme_minimal() +
    labs(title = "Densidad del Consumo por Hora y Cluster",
         x = "Hora del d√≠a",
         y = "Densidad",
         color = "Cluster",
         fill = "Cluster") +
    scale_x_continuous(breaks = seq(0, 23, by = 1)) +  # Asegura que se muestren todas las horas
    theme(legend.position = "top")
  
  print(p)  # Mostrar el gr√°fico
}

# üìå **Ejemplo de uso**
graficar_densidad_horas(datos_clusterizados)

```

Tabla de probabilidad de pertenencia por dia (seleccionar dia de interes)

```{r}

# Tabla Probabilidad dia_semana - hora - Clusters (consulta por dia) #####

#solo tabla

# library(ggplot2)
# library(dplyr)
# library(tidyr)
# library(DT)
# 
# calcular_probabilidad_por_dia <- function(datos) {
#   # Obtener nombres de los clusters din√°micamente
#   cluster_cols <- grep("^cluster_", colnames(datos), value = TRUE)
#   
#   # Agrupar por d√≠a de la semana y hora, calculando promedio de pertenencia a cada cluster
#   probabilidad_por_hora <- datos %>%
#     group_by(dia_sem, hora) %>%
#     summarise(across(all_of(cluster_cols), mean, na.rm = TRUE), .groups = "drop")
#   
#   # Crear una lista para almacenar las tablas
#   tablas_dias <- list()
#   
#   # Generar una tabla DT por cada d√≠a de la semana
#   for (dia in unique(probabilidad_por_hora$dia_sem)) {
#     tabla_dt <- probabilidad_por_hora %>%
#       filter(dia_sem == dia) %>%
#       datatable(options = list(pageLength = 24, scrollX = TRUE),
#                 caption = paste("Probabilidad de pertenencia por hora -", dia))
#     
#     tablas_dias[[as.character(dia)]] <- tabla_dt
#   }
#   
#   return(tablas_dias)
# }
# 
# # L√≠nea de prueba
# tablas_probabilidad <- calcular_probabilidad_por_dia(datos_con_probabilidad)
# 
# # Para visualizar una tabla espec√≠fica (ejemplo: Lunes)
# tablas_probabilidad[["martes"]]


```

```{r}
#version anterior de tabla y grafico
# library(ggplot2)
# library(dplyr)
# library(tidyr)
# library(DT)
# 
# # Funci√≥n para calcular tabla y gr√°fico de probabilidades por d√≠a
# calcular_probabilidad_por_dia <- function(datos) {
#   # Obtener nombres de los clusters din√°micamente
#   cluster_cols <- grep("^cluster_", colnames(datos), value = TRUE)
#   
#   # Agrupar por d√≠a de la semana y hora, calculando promedio de pertenencia a cada cluster
#   probabilidad_por_hora <- datos %>%
#     group_by(dia_sem, hora) %>%
#     summarise(across(all_of(cluster_cols), mean, na.rm = TRUE), .groups = "drop")
#   
#   # Crear una lista para almacenar las tablas y gr√°ficos
#   resultados <- list()
#   
#   # Generar una tabla DT y un gr√°fico por cada d√≠a de la semana
#   for (dia in unique(probabilidad_por_hora$dia_sem)) {
#     # Filtrar los datos para el d√≠a espec√≠fico
#     datos_dia <- probabilidad_por_hora %>% filter(dia_sem == dia)
#     
#     # Convertir a formato largo para ggplot
#     datos_long <- datos_dia %>%
#       pivot_longer(cols = all_of(cluster_cols), names_to = "Cluster", values_to = "Probabilidad")
#     
#     # Crear tabla interactiva
#     tabla_dt <- datatable(datos_dia, options = list(pageLength = 24, scrollX = TRUE),
#                           caption = paste("Probabilidad de pertenencia por hora -", dia))
#     
#     # Crear gr√°fico de l√≠neas
#     grafico <- ggplot(datos_long, aes(x = hora, y = Probabilidad, color = Cluster)) +
#       geom_line(size = 1) +
#       geom_point(size = 2) +
#       scale_x_continuous(breaks = seq(0, 23, by = 1)) +
#       labs(title = paste("Evoluci√≥n de Probabilidades -", dia),
#            x = "Hora del d√≠a",
#            y = "Probabilidad de pertenencia",
#            color = "Cluster") +
#       theme_minimal()
#     
#     # Almacenar en la lista
#     resultados[[as.character(dia)]] <- list(tabla = tabla_dt, grafico = grafico)
#   }
#   
#   return(resultados)
# }
# 
# #L√≠nea de prueba
# resultados_probabilidad <- calcular_probabilidad_por_dia(datos_con_probabilidad)
# #Para visualizar resultados
# resultados_probabilidad[["martes"]]$tabla
# resultados_probabilidad[["martes"]]$grafico

```

```{r}

library(ggplot2)
library(dplyr)
library(tidyr)
library(DT)
library(scales)

# Funci√≥n para obtener colores consistentes
obtener_colores_clusters <- function(datos_clusterizados) {
  clusters_unicos <- sort(unique(datos_clusterizados$Cluster))  # Ordenar clusters √∫nicos
  num_clusters <- length(clusters_unicos)

  # Definir los dos primeros colores fijos
  colores_fijos <- c("cluster_1" = "blue", "cluster_2" = "red")  

  # Si hay m√°s clusters, generar colores adicionales con hue_pal()
  if (num_clusters > 2) {
    clusters_adicionales <- setdiff(clusters_unicos, c("cluster_1", "cluster_2"))
    colores_extra <- hue_pal()(length(clusters_adicionales))  # Colores adicionales
    nombres_clusters_extra <- as.character(clusters_adicionales)
    nombres_colores_extra <- setNames(colores_extra, nombres_clusters_extra)

    # Combinar colores fijos con los adicionales
    colores_finales <- c(colores_fijos, nombres_colores_extra)
  } else {
    colores_finales <- colores_fijos
  }

  return(colores_finales)
}

# Funci√≥n para calcular tabla y gr√°fico de probabilidades por d√≠a
calcular_probabilidad_por_dia <- function(datos) {
  # Obtener nombres de los clusters din√°micamente
  cluster_cols <- grep("^cluster_", colnames(datos), value = TRUE)
  
  # Agrupar por d√≠a de la semana y hora, calculando promedio de pertenencia a cada cluster
  probabilidad_por_hora <- datos %>%
    group_by(dia_sem, hora) %>%
    summarise(across(all_of(cluster_cols), mean, na.rm = TRUE), .groups = "drop")
  
  # Crear una lista para almacenar las tablas y gr√°ficos
  resultados <- list()
  
  # Generar una tabla DT y un gr√°fico por cada d√≠a de la semana
  for (dia in unique(probabilidad_por_hora$dia_sem)) {
    # Filtrar los datos para el d√≠a espec√≠fico
    datos_dia <- probabilidad_por_hora %>% filter(dia_sem == dia)
    
    # Convertir a formato largo para ggplot
    datos_long <- datos_dia %>%
      pivot_longer(cols = all_of(cluster_cols), names_to = "Cluster", values_to = "Probabilidad")
    
    # Obtener colores para los clusters
    colores <- obtener_colores_clusters(datos_long)
    
    # Crear tabla interactiva
    tabla_dt <- datatable(datos_dia, options = list(pageLength = 24, scrollX = TRUE),
                          caption = paste("Probabilidad de pertenencia por hora -", dia))
    
    # Crear gr√°fico de l√≠neas
    grafico <- ggplot(datos_long, aes(x = hora, y = Probabilidad, color = Cluster)) +
      geom_line(size = 1) +
      geom_point(size = 2) +
      scale_x_continuous(breaks = seq(0, 23, by = 1)) +
      scale_color_manual(values = colores) +
      labs(title = paste("Evoluci√≥n de Probabilidades -", dia),
           x = "Hora del d√≠a",
           y = "Probabilidad de pertenencia",
           color = "Cluster") +
      theme_minimal()
    
    # Almacenar en la lista
    resultados[[as.character(dia)]] <- list(tabla = tabla_dt, grafico = grafico)
  }
  
  return(resultados)
}

# L√≠nea de prueba
resultados_probabilidad <- calcular_probabilidad_por_dia(datos_con_probabilidad)
# Para visualizar resultados
resultados_probabilidad[["martes"]]$tabla
resultados_probabilidad[["martes"]]$grafico

```

#### 

Tabla y matriz de franjas horarias

```{r}
# matriz dia hora cluster dominante  #####
# Funci√≥n para generar tabla y matriz con cluster dominante de cada hora en el dia (semana completa)#####
# genera una tabla y una matriz con los dias de la semana y las 24h con su cluster dominante absoluto y por % de pertenencia (puede haber mixto si no supera umbral)


# library(ggplot2)
# library(dplyr)
# library(tidyr)
# library(DT)
# 
# # Funci√≥n para generar tabla completa con cluster dominante considerando un umbral de probabilidad
# generar_tabla_probabilidad_completa <- function(datos_probabilidad, umbral_probabilidad = 0.7) {
#   
#   # Agrupar por d√≠a de la semana y hora, calculando el promedio de probabilidad por cluster
#   tabla_probabilidad <- datos_probabilidad %>%
#     group_by(dia_sem, hora) %>%
#     summarise(across(starts_with("cluster_"), mean, na.rm = TRUE)) %>%
#     ungroup()
#   
#   # Determinar el cluster dominante con el umbral definido
#   max_probabilidad <- apply(tabla_probabilidad %>% select(starts_with("cluster_")), 1, max)
#   cluster_dominante <- apply(tabla_probabilidad %>% select(starts_with("cluster_")), 1, 
#                              function(x) ifelse(max(x) >= umbral_probabilidad, names(x)[which.max(x)], "Mixto"))
#   
#   # Limpiar nombres de los clusters
#   tabla_probabilidad$cluster_dominante <- gsub("cluster_", "", cluster_dominante)
#   
#   # Mostrar en formato DT
#   datatable(tabla_probabilidad, options = list(pageLength = 10, scrollX = TRUE))
#   
#   return(tabla_probabilidad)
# }
# 
# # Funci√≥n para generar matriz de cluster dominante
# generar_matriz_clusters <- function(tabla_probabilidad) {
#   
#   # Convertir la tabla en formato largo para la matriz visual
#   tabla_probabilidad <- tabla_probabilidad %>%
#     mutate(dia_sem = factor(dia_sem, levels = c("lunes", "martes", "mi√©rcoles", "jueves", "viernes", "s√°bado", "domingo")))
#   
#   # Crear la matriz visual con ggplot
#   matriz <- ggplot(tabla_probabilidad, aes(x = factor(hora, levels = 0:23), y = dia_sem, fill = cluster_dominante)) +
#     geom_tile(color = "white") +
#     scale_fill_manual(values = c("1" = "red", "2" = "blue", "3" = "green", "4" = "purple", "5" = "orange", "Mixto" = "gray")) +
#     labs(title = "Matriz de Cluster Dominante por D√≠a y Hora",
#          x = "Hora del D√≠a",
#          y = "D√≠a de la Semana",
#          fill = "Cluster Dominante") +
#     theme_minimal()
#   
#   print(matriz)  # Mostrar el gr√°fico
# }
# 
# # Ejemplo de uso:
# tabla_completa_abs <- generar_tabla_probabilidad_completa(datos_con_probabilidad, umbral_probabilidad = 0.5)
# tabla_completa <- generar_tabla_probabilidad_completa(datos_con_probabilidad, umbral_probabilidad = 0.6)
# generar_matriz_clusters(tabla_completa_abs)
# generar_matriz_clusters(tabla_completa)


```

```{r}
# library(ggplot2)
# library(dplyr)
# library(tidyr)
# library(DT)
# library(scales)  # Para colores hue_pal()
# 
# # Funci√≥n para obtener colores consistentes
# generar_colores_clusters <- function(tabla_probabilidad) {
#   clusters_unicos <- unique(tabla_probabilidad$cluster_dominante)
#   clusters_unicos <- sort(clusters_unicos[clusters_unicos != "Mixto"])  # Ordenar y excluir "Mixto"
#   num_clusters <- length(clusters_unicos)
# 
#   # Definir el color fijo para "Mixto"
#   colores_fijos <- c("Mixto" = "gray")
# 
#   # Generar colores adicionales con hue_pal() para los clusters
#   colores_extra <- hue_pal()(num_clusters)  # Generar colores distintos
#   nombres_colores_extra <- setNames(colores_extra, clusters_unicos)
# 
#   # Combinar colores fijos con los generados din√°micamente
#   colores_finales <- c(colores_fijos, nombres_colores_extra)
#   return(colores_finales)
# }
# 
# # Funci√≥n para generar tabla completa con cluster dominante considerando un umbral de probabilidad
# generar_tabla_probabilidad_completa <- function(datos_probabilidad, umbral_probabilidad = 0.7) {
#   
#   # Agrupar por d√≠a de la semana y hora, calculando el promedio de probabilidad por cluster
#   tabla_probabilidad <- datos_probabilidad %>%
#     group_by(dia_sem, hora) %>%
#     summarise(across(starts_with("cluster_"), mean, na.rm = TRUE)) %>%
#     ungroup()
#   
#   # Determinar el cluster dominante con el umbral definido
#   max_probabilidad <- apply(tabla_probabilidad %>% select(starts_with("cluster_")), 1, max)
#   cluster_dominante <- apply(tabla_probabilidad %>% select(starts_with("cluster_")), 1, 
#                              function(x) ifelse(max(x) >= umbral_probabilidad, names(x)[which.max(x)], "Mixto"))
#   
#   # Limpiar nombres de los clusters
#   tabla_probabilidad$cluster_dominante <- gsub("cluster_", "", cluster_dominante)
#   
#   # Mostrar en formato DT
#   datatable(tabla_probabilidad, options = list(pageLength = 10, scrollX = TRUE))
#   
#   return(tabla_probabilidad)
# }
# 
# # Funci√≥n para generar matriz de cluster dominante
# generar_matriz_clusters <- function(tabla_probabilidad) {
#   
#   # Obtener colores din√°micos
#   colores_clusters <- generar_colores_clusters(tabla_probabilidad)
#   
#   # Convertir la tabla en formato largo para la matriz visual
#   tabla_probabilidad <- tabla_probabilidad %>%
#     mutate(dia_sem = factor(dia_sem, levels = c("lunes", "martes", "mi√©rcoles", "jueves", "viernes", "s√°bado", "domingo")))
#   
#   # Crear la matriz visual con ggplot
#   matriz <- ggplot(tabla_probabilidad, aes(x = factor(hora, levels = 0:23), y = dia_sem, fill = cluster_dominante)) +
#     geom_tile(color = "white") +
#     scale_fill_manual(values = colores_clusters) +
#     labs(title = "Matriz de Cluster Dominante por D√≠a y Hora",
#          x = "Hora del D√≠a",
#          y = "D√≠a de la Semana",
#          fill = "Cluster Dominante") +
#     theme_minimal()
#   
#   print(matriz)  # Mostrar el gr√°fico
# }
# 
# # Ejemplo de uso:
# tabla_completa_abs <- generar_tabla_probabilidad_completa(datos_con_probabilidad, umbral_probabilidad = 0.5)
# tabla_completa <- generar_tabla_probabilidad_completa(datos_con_probabilidad, umbral_probabilidad = 0.6)
# generar_matriz_clusters(tabla_completa_abs)
# generar_matriz_clusters(tabla_completa)

```

```{r}
# library(ggplot2)
# library(dplyr)
# library(tidyr)
# library(DT)
# 
# # Funci√≥n para generar tabla completa con cluster dominante considerando un umbral de probabilidad
# generar_tabla_probabilidad_completa <- function(datos_probabilidad, umbral_probabilidad = 0.7) {
#   
#   # Agrupar por d√≠a de la semana y hora, calculando el promedio de probabilidad por cluster
#   tabla_probabilidad <- datos_probabilidad %>%
#     group_by(dia_sem, hora) %>%
#     summarise(across(starts_with("cluster_"), mean, na.rm = TRUE)) %>%
#     ungroup()
#   
#   # Determinar el cluster dominante con el umbral definido
#   max_probabilidad <- apply(tabla_probabilidad %>% select(starts_with("cluster_")), 1, max)
#   cluster_dominante <- apply(tabla_probabilidad %>% select(starts_with("cluster_")), 1, 
#                              function(x) ifelse(max(x) >= umbral_probabilidad, names(x)[which.max(x)], "Mixto"))
#   
#   # Limpiar nombres de los clusters
#   tabla_probabilidad$cluster_dominante <- gsub("cluster_", "", cluster_dominante)
#   
#   # Mostrar en formato DT
#   datatable(tabla_probabilidad, options = list(pageLength = 10, scrollX = TRUE))
#   
#   return(tabla_probabilidad)
# }
# 
# # Funci√≥n para generar matriz de cluster dominante
# generar_matriz_clusters <- function(tabla_probabilidad) {
#   
#   # Convertir la tabla en formato largo para la matriz visual
#   tabla_probabilidad <- tabla_probabilidad %>%
#     mutate(dia_sem = factor(dia_sem, levels = c("lunes", "martes", "mi√©rcoles", "jueves", "viernes", "s√°bado", "domingo")))
#   
#   # Obtener colores con la funci√≥n definida previamente
#   colores_clusters <- obtener_colores_clusters(tabla_probabilidad)
#   
#   # Agregar el color gris para "Mixto"
#   colores_clusters["Mixto"] <- "gray"
#   
#   # Crear la matriz visual con ggplot
#   matriz <- ggplot(tabla_probabilidad, aes(x = factor(hora, levels = 0:23), y = dia_sem, fill = cluster_dominante)) +
#     geom_tile(color = "white") +
#     scale_fill_manual(values = colores_clusters) +
#     labs(title = "Matriz de Cluster Dominante por D√≠a y Hora",
#          x = "Hora del D√≠a",
#          y = "D√≠a de la Semana",
#          fill = "Cluster Dominante") +
#     theme_minimal()
#   
#   print(matriz)  # Mostrar el gr√°fico
# }
# 
# # Ejemplo de uso:
# tabla_completa_abs <- generar_tabla_probabilidad_completa(datos_con_probabilidad, umbral_probabilidad = 0.5)
# tabla_completa <- generar_tabla_probabilidad_completa(datos_con_probabilidad, umbral_probabilidad = 0.6)
# generar_matriz_clusters(tabla_completa_abs)
# generar_matriz_clusters(tabla_completa)

```

```{r}
library(ggplot2)
library(dplyr)
library(tidyr)
library(DT)

# Funci√≥n para obtener colores consistentes
obtener_colores_clusters <- function(datos_clusterizados) {
  clusters_unicos <- sort(unique(datos_clusterizados$cluster))  # Ordenar clusters √∫nicos
  num_clusters <- length(clusters_unicos)

  # Definir los dos primeros colores fijos
  colores_fijos <- c("1" = "blue", "2" = "red")  

  # Si hay m√°s clusters, generar colores adicionales con hue_pal()
  if (num_clusters > 2) {
    clusters_adicionales <- setdiff(clusters_unicos, c(1, 2))
    colores_extra <- hue_pal()(length(clusters_adicionales))  # Colores adicionales
    nombres_clusters_extra <- as.character(clusters_adicionales)
    nombres_colores_extra <- setNames(colores_extra, nombres_clusters_extra)

    # Combinar colores fijos con los adicionales
    colores_finales <- c(colores_fijos, nombres_colores_extra)
  } else {
    colores_finales <- colores_fijos
  }

  colores_finales["Mixto"] <- "gray"  # Agregar color fijo para "Mixto"
  return(colores_finales)
}

# Funci√≥n para generar tabla completa con cluster dominante considerando un umbral de probabilidad
generar_tabla_probabilidad_completa <- function(datos_probabilidad, umbral_probabilidad = 0.7) {
  
  # Agrupar por d√≠a de la semana y hora, calculando el promedio de probabilidad por cluster
  tabla_probabilidad <- datos_probabilidad %>%
    group_by(dia_sem, hora) %>%
    summarise(across(starts_with("cluster_"), mean, na.rm = TRUE)) %>%
    ungroup()
  
  # Determinar el cluster dominante con el umbral definido
  max_probabilidad <- apply(tabla_probabilidad %>% select(starts_with("cluster_")), 1, max)
  cluster_dominante <- apply(tabla_probabilidad %>% select(starts_with("cluster_")), 1, 
                             function(x) ifelse(max(x) >= umbral_probabilidad, names(x)[which.max(x)], "Mixto"))
  
  # Limpiar nombres de los clusters
  tabla_probabilidad$cluster_dominante <- gsub("cluster_", "", cluster_dominante)
  
  # Mostrar en formato DT
  datatable(tabla_probabilidad, options = list(pageLength = 10, scrollX = TRUE))
  
  return(tabla_probabilidad)
}

# Funci√≥n para generar matriz de cluster dominante
generar_matriz_clusters <- function(tabla_probabilidad) {
  
  # Convertir la tabla en formato largo para la matriz visual
  tabla_probabilidad <- tabla_probabilidad %>%
    mutate(dia_sem = factor(dia_sem, levels = c("lunes", "martes", "mi√©rcoles", "jueves", "viernes", "s√°bado", "domingo")))
  
  # Obtener colores basados en los clusters detectados
  colores_clusters <- obtener_colores_clusters(tabla_probabilidad)
  
  # Crear la matriz visual con ggplot
  matriz <- ggplot(tabla_probabilidad, aes(x = factor(hora, levels = 0:23), y = dia_sem, fill = cluster_dominante)) +
    geom_tile(color = "white") +
    scale_fill_manual(values = colores_clusters) +
    labs(title = "Matriz de Cluster Dominante por D√≠a y Hora",
         x = "Hora del D√≠a",
         y = "D√≠a de la Semana",
         fill = "Cluster Dominante") +
    theme_minimal()
  
  print(matriz)  # Mostrar el gr√°fico
}

```

Umbral 50%

```{r}
tabla_completa <- generar_tabla_probabilidad_completa(datos_con_probabilidad, umbral_probabilidad = 0.5)

generar_matriz_clusters(tabla_completa)
```

Umbral 60%

```{r}
tabla_completa_umbral <- generar_tabla_probabilidad_completa(datos_con_probabilidad, umbral_probabilidad = 0.6)

generar_matriz_clusters(tabla_completa_umbral)
```

Tabla franjas

```{r}
# Funci√≥n para consolidar las franjas horarias por cluster y d√≠a #####
#' resume y organiza las tablas anteriores en una tabla con las franjas horarias en los dias de la semana para cada cluster
#' crea un excel para editar las frnajas horarias de los cluster
#' se editan las franjas por si el usuario quiere ajustar (uniformar los cluster, ej que todos empeicen a la misma hora)
#' fusiona el excel con datos clusterizados para tener datos clusterizados por algoritmo y editado


library(dplyr)
library(openxlsx)

# Funci√≥n para consolidar franjas horarias en un dataframe
consolidar_franjas_horarias <- function(tabla) {
  niveles_dias <- c("domingo", "lunes", "martes", "mi√©rcoles", "jueves", "viernes", "s√°bado")
  
  agrupar_horas <- function(horas) {
    rle_horas <- rle(horas)
    valores <- rle_horas$values
    grupos <- split(valores, cumsum(c(1, diff(valores) != 1)))
    
    franjas <- sapply(grupos, function(g) {
      if (length(g) > 1) {
        paste0(min(g), "-", max(g))
      } else {
        as.character(g)
      }
    })
    
    paste(franjas, collapse = ", ")
  }
  
  tabla_franjas <- tabla %>%
    mutate(dia_sem = factor(dia_sem, levels = niveles_dias)) %>%
    arrange(dia_sem, hora, cluster_dominante) %>%
    group_by(dia_sem, cluster_dominante) %>%
    summarise(franja_horaria = agrupar_horas(hora), .groups = "drop")
  
  return(tabla_franjas)  # Retorna como un data.frame
}




```

```{r}
# Generar la tabla

tabla_franjas <- consolidar_franjas_horarias(tabla_completa)
datatable(tabla_franjas, options = list(pageLength = 20, scrollX = TRUE))

```

```{r}
#Generar la tabla
tabla_franjas_umbral <- consolidar_franjas_horarias(tabla_completa_umbral)
datatable(tabla_franjas_umbral, options = list(pageLength = 20, scrollX = TRUE))
```

```{r}
# # Exportar a Excel
# write.xlsx(tabla_franjas, "tabla_franjas.xlsx")
# 
# print("Archivo tabla_franjas.xlsx guardado. Ed√≠talo y luego c√°rgalo de nuevo.")


```

#### Interpretaci√≥n de grupos

Observaciones generales de analisis exploratorio e interpretacion de grupos

## Edici√≥n o Ajuste de Grupos (si aplica)

### Validaci√≥n de grupos editado

### Exploraci√≥n e interpretaci√≥n de grupos editado

## Modelos de LB

### Construcci√≥n

### Metricas

### Comparaciones contra modelos sin agrupaciones

## Observaciones Generales
